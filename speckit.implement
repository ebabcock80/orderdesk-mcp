# Implementation Guide: OrderDesk MCP Server + Optional WebUI

**Version:** 1.0  
**Status:** Active Implementation Roadmap  
**Last Updated:** October 17, 2025  
**Purpose:** Consolidated, actionable implementation steps ready for coding

**Prerequisites:**
- Review [`speckit.constitution`](./speckit.constitution) - Design principles
- Review [`speckit.specify`](./speckit.specify) - Technical specification
- Answer critical questions in [`speckit.clarify`](./speckit.clarify) (Q1, Q3, Q4, Q6, Q9, Q11, Q13)
- Review [`speckit.analyze`](./speckit.analyze) - 96.4% alignment confirmed, ready to proceed

**Companion Documents:**
- [`speckit.plan`](./speckit.plan) - 8-phase implementation plan
- [`speckit.tasks.v1.1`](./speckit.tasks.v1.1.md) - Granular task breakdown
- [`speckit.checklist`](./speckit.checklist) - Quality validation (~300 items)

---

## Implementation Philosophy

### Core Principles
1. **MCP stdio is primary** - HTTP/WebUI is optional and feature-flagged
2. **Test-first development** - Write tests before or alongside implementation
3. **Incremental validation** - Each step delivers working, tested functionality
4. **Security by default** - Encryption, redaction, CSRF from day one
5. **Wide first, deep second** - Build breadth (all tools) before depth (optimizations)

### Context
- **WebUI Purpose:** Admin/testing only - onboarding, store CRUD, API Test Console, traces
- **Not a Dashboard:** Use OrderDesk's native UI for day-to-day operations
- **Feature-Flagged:** All optional features disabled by default, documented

---

## Implementation Steps

## Step 1: Core Foundation

**Goal:** Establish secure, observable, resilient platform infrastructure

**Duration:** ~80 hours (Phase 0-1)  
**Dependencies:** None  
**Validation:** Phase 0-1 exit criteria from plan

### 1.1 Bootstrap (Phase 0)

#### Directory Structure
```bash
mkdir -p mcp_server/{auth,models,routers,services,utils,webui}
mkdir -p tests/{unit,integration,e2e}
mkdir -p docs examples
touch mcp_server/__init__.py mcp_server/{main.py,mcp_server.py,config.py}
```

#### Dependencies (`pyproject.toml`)
```toml
[project]
name = "orderdesk-mcp-server"
version = "0.1.0-alpha"
requires-python = ">=3.11"

dependencies = [
    "mcp>=1.0.0",
    "httpx>=0.27.0",
    "pydantic>=2.8",
    "pydantic-settings>=2.0",
    "sqlalchemy>=2.0",
    "cryptography>=42.0",
    "python-jose>=3.3",  # For JWT
    "bcrypt>=4.0",
]

[project.optional-dependencies]
webui = [
    "fastapi>=0.111",
    "jinja2>=3.1",
    "python-multipart>=0.0.9",
]
dev = [
    "pytest>=8.0",
    "pytest-asyncio>=0.23",
    "pytest-cov>=4.1",
    "pytest-mock>=3.12",
    "ruff>=0.3",
    "mypy>=1.9",
    "black>=24.0",
]
```

#### Docker Configuration
```dockerfile
# Dockerfile (multi-stage)
FROM python:3.11-slim as builder
WORKDIR /app
COPY pyproject.toml ./
RUN pip install --no-cache-dir -e .[webui]

FROM python:3.11-slim
WORKDIR /app
RUN useradd -m -u 1000 appuser
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY mcp_server ./mcp_server
RUN chown -R appuser:appuser /app
USER appuser
VOLUME /app/data
HEALTHCHECK CMD python -c "import sys; sys.exit(0)"
CMD ["python", "-m", "mcp_server.main"]
```

#### Environment Configuration
```python
# mcp_server/config.py
from pydantic_settings import BaseSettings, SettingsConfigDict
from pydantic import Field, field_validator
import base64

class Settings(BaseSettings):
    model_config = SettingsConfigDict(env_file='.env', case_sensitive=False)
    
    # Required
    mcp_kms_key: str = Field(..., description="Master encryption key (base64, 32+ bytes)")
    
    # Core
    port: int = Field(8080, ge=1024, le=65535)
    database_url: str = "sqlite:///data/app.db"
    log_level: str = "INFO"
    
    # Security
    trust_proxy: bool = False
    rate_limit_rpm: int = 120
    auto_provision_tenant: bool = False
    
    # Cache
    cache_backend: str = "memory"
    cache_ttl_orders: int = 15
    cache_ttl_products: int = 60
    
    # WebUI (optional)
    enable_webui: bool = False
    enable_public_signup: bool = False
    jwt_secret_key: str | None = None
    session_timeout: int = 86400  # 24 hours
    
    @field_validator('mcp_kms_key')
    def validate_kms_key(cls, v):
        try:
            decoded = base64.b64decode(v)
            if len(decoded) < 32:
                raise ValueError("MCP_KMS_KEY must be at least 32 bytes")
        except Exception as e:
            raise ValueError(f"Invalid MCP_KMS_KEY: {e}")
        return v
    
    @field_validator('jwt_secret_key')
    def validate_jwt_secret(cls, v, info):
        if info.data.get('enable_webui') and not v:
            raise ValueError("JWT_SECRET_KEY required when ENABLE_WEBUI=true")
        return v

settings = Settings()
```

### 1.2 Cryptography (Phase 1)

#### HKDF Key Derivation
```python
# mcp_server/auth/crypto.py
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.hkdf import HKDF
from cryptography.hazmat.backends import default_backend
import base64
import os

def derive_tenant_key(master_key: str, salt: str) -> bytes:
    """
    Derive per-tenant encryption key using HKDF-SHA256.
    
    Args:
        master_key: Tenant's master key (plaintext, in memory only)
        salt: Random salt stored in database
    
    Returns:
        32-byte AES key
    """
    from mcp_server.config import settings
    
    kms_key = base64.b64decode(settings.mcp_kms_key)
    info = f"orderdesk-mcp-tenant-{salt}".encode()
    
    hkdf = HKDF(
        algorithm=hashes.SHA256(),
        length=32,
        salt=salt.encode(),
        info=info,
        backend=default_backend()
    )
    
    return hkdf.derive(master_key.encode())
```

#### AES-256-GCM Encryption
```python
# mcp_server/auth/crypto.py (continued)
from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes

def encrypt_api_key(api_key: str, tenant_key: bytes) -> tuple[str, str, str]:
    """
    Encrypt API key using AES-256-GCM.
    
    Returns:
        (ciphertext_b64, tag_b64, nonce_b64)
    """
    nonce = os.urandom(12)  # 96 bits for GCM
    cipher = Cipher(
        algorithms.AES(tenant_key),
        modes.GCM(nonce),
        backend=default_backend()
    )
    encryptor = cipher.encryptor()
    
    ciphertext = encryptor.update(api_key.encode()) + encryptor.finalize()
    
    return (
        base64.b64encode(ciphertext).decode(),
        base64.b64encode(encryptor.tag).decode(),
        base64.b64encode(nonce).decode()
    )

def decrypt_api_key(ciphertext: str, tag: str, nonce: str, tenant_key: bytes) -> str:
    """Decrypt API key with tag verification."""
    cipher = Cipher(
        algorithms.AES(tenant_key),
        modes.GCM(base64.b64decode(nonce), base64.b64decode(tag)),
        backend=default_backend()
    )
    decryptor = cipher.decryptor()
    
    plaintext = decryptor.update(base64.b64decode(ciphertext)) + decryptor.finalize()
    return plaintext.decode()
```

#### Master Key Hashing
```python
# mcp_server/auth/crypto.py (continued)
import bcrypt

def hash_master_key(master_key: str) -> tuple[str, str]:
    """Hash master key with bcrypt. Returns (hash, salt)."""
    salt = bcrypt.gensalt()
    hashed = bcrypt.hashpw(master_key.encode(), salt)
    return hashed.decode(), salt.decode()

def verify_master_key(master_key: str, stored_hash: str) -> bool:
    """Verify master key against stored hash (constant-time)."""
    return bcrypt.checkpw(master_key.encode(), stored_hash.encode())
```

### 1.3 Database Schema

```python
# mcp_server/models/database.py
from sqlalchemy import Column, String, Integer, Boolean, DateTime, ForeignKey, Index
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid

Base = declarative_base()

class Tenant(Base):
    __tablename__ = "tenants"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    master_key_hash = Column(String, nullable=False)
    salt = Column(String, nullable=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    
    __table_args__ = (
        Index('idx_tenants_master_key_hash', 'master_key_hash'),
    )

class Store(Base):
    __tablename__ = "stores"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    tenant_id = Column(String, ForeignKey('tenants.id', ondelete='CASCADE'), nullable=False)
    store_id = Column(String, nullable=False)  # OrderDesk store ID
    store_name = Column(String, nullable=False)  # Friendly name
    label = Column(String, nullable=True)
    api_key_ciphertext = Column(String, nullable=False)
    api_key_tag = Column(String, nullable=False)
    api_key_nonce = Column(String, nullable=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    
    __table_args__ = (
        Index('idx_stores_tenant_id', 'tenant_id'),
        Index('idx_stores_store_name', 'tenant_id', 'store_name'),
        # Unique constraints
        # Note: SQLAlchemy will create indices for unique constraints
    )
```

### 1.4 Logging & Tracing

```python
# mcp_server/utils/logging.py
import logging
import json
from typing import Any
from contextvars import ContextVar

# Context vars for request tracing
correlation_id_var: ContextVar[str] = ContextVar('correlation_id', default='')
tenant_id_var: ContextVar[str] = ContextVar('tenant_id', default='')
store_id_var: ContextVar[str] = ContextVar('store_id', default='')

REDACTED_FIELDS = {
    'master_key', 'api_key', 'api_key_ciphertext', 
    'password', 'token', 'secret', 'authorization',
    'jwt_secret_key', 'session_token'
}

def redact_secrets(data: Any) -> Any:
    """Recursively redact sensitive fields."""
    if isinstance(data, dict):
        return {
            k: '[REDACTED]' if k.lower() in REDACTED_FIELDS else redact_secrets(v)
            for k, v in data.items()
        }
    elif isinstance(data, list):
        return [redact_secrets(item) for item in data]
    return data

class StructuredLogger(logging.LoggerAdapter):
    """Logger that outputs structured JSON with context."""
    
    def process(self, msg, kwargs):
        extra = kwargs.get('extra', {})
        extra.update({
            'correlation_id': correlation_id_var.get(),
            'tenant_id': tenant_id_var.get(),
            'store_id': store_id_var.get(),
        })
        # Redact secrets
        extra = redact_secrets(extra)
        kwargs['extra'] = extra
        return msg, kwargs
```

### 1.5 Session Context

```python
# mcp_server/services/session.py
from contextvars import ContextVar
from dataclasses import dataclass
import uuid

@dataclass
class SessionContext:
    """Session context for MCP requests."""
    tenant_id: str | None = None
    tenant_key: bytes | None = None
    active_store_id: str | None = None
    correlation_id: str | None = None
    
    def __post_init__(self):
        if not self.correlation_id:
            self.correlation_id = str(uuid.uuid4())

# Global context var (scoped per async task)
session_context: ContextVar[SessionContext] = ContextVar(
    'session_context',
    default=SessionContext()
)

def get_context() -> SessionContext:
    """Get current session context."""
    return session_context.get()

def set_context(ctx: SessionContext):
    """Set session context."""
    session_context.set(ctx)
```

### 1.6 OrderDesk HTTP Client

```python
# mcp_server/services/orderdesk.py
import httpx
import asyncio
import random
from typing import Any

class OrderDeskClient:
    """Async HTTP client for OrderDesk API with retries."""
    
    BASE_URL = "https://app.orderdesk.me/api/v2"
    
    def __init__(self, store_id: str, api_key: str):
        self.store_id = store_id
        self.api_key = api_key
        self.client = httpx.AsyncClient(
            base_url=self.BASE_URL,
            timeout=httpx.Timeout(30.0, connect=5.0),
            headers={
                "ORDERDESK-STORE-ID": store_id,
                "ORDERDESK-API-KEY": api_key,
            }
        )
    
    async def get(self, endpoint: str, params: dict | None = None) -> dict:
        """GET with automatic retry on 429/5xx."""
        return await self._retry_with_backoff(
            lambda: self.client.get(endpoint, params=params)
        )
    
    async def post(self, endpoint: str, data: dict) -> dict:
        """POST with automatic retry."""
        return await self._retry_with_backoff(
            lambda: self.client.post(endpoint, json=data)
        )
    
    async def put(self, endpoint: str, data: dict) -> dict:
        """PUT with automatic retry."""
        return await self._retry_with_backoff(
            lambda: self.client.put(endpoint, json=data)
        )
    
    async def delete(self, endpoint: str) -> dict:
        """DELETE with automatic retry."""
        return await self._retry_with_backoff(
            lambda: self.client.delete(endpoint)
        )
    
    async def _retry_with_backoff(self, request_fn, max_retries: int = 3) -> dict:
        """Retry with exponential backoff on 429/5xx."""
        for attempt in range(max_retries):
            try:
                response = await request_fn()
                
                # Parse rate limit headers
                tokens_remaining = response.headers.get('X-Tokens-Remaining')
                retry_after = response.headers.get('X-Retry-After')
                
                if tokens_remaining:
                    logger.info(f"OD tokens remaining: {tokens_remaining}")
                
                if response.status_code == 429:
                    # Rate limited
                    wait = int(retry_after) if retry_after else (2 ** attempt)
                    logger.warning(f"Rate limited, waiting {wait}s")
                    await asyncio.sleep(wait)
                    continue
                
                if response.status_code >= 500:
                    # Server error - retry with backoff
                    wait = (2 ** attempt) + random.uniform(0, 1)
                    logger.warning(f"Server error {response.status_code}, retrying in {wait}s")
                    await asyncio.sleep(wait)
                    continue
                
                response.raise_for_status()
                return response.json()
                
            except httpx.TimeoutException:
                if attempt == max_retries - 1:
                    raise
                wait = (2 ** attempt) + random.uniform(0, 1)
                await asyncio.sleep(wait)
        
        raise Exception(f"Max retries ({max_retries}) exceeded")
```

### 1.7 Cache Layer

```python
# mcp_server/services/cache.py
from abc import ABC, abstractmethod
from typing import Any
import time

class CacheBackend(ABC):
    @abstractmethod
    async def get(self, key: str) -> Any | None: pass
    
    @abstractmethod
    async def set(self, key: str, value: Any, ttl: int): pass
    
    @abstractmethod
    async def delete(self, key: str): pass
    
    @abstractmethod
    async def delete_pattern(self, pattern: str): pass

class MemoryCache(CacheBackend):
    """In-memory cache with TTL."""
    
    def __init__(self):
        self._cache: dict[str, tuple[Any, float]] = {}
    
    async def get(self, key: str) -> Any | None:
        if key in self._cache:
            value, expires_at = self._cache[key]
            if time.time() < expires_at:
                return value
            del self._cache[key]
        return None
    
    async def set(self, key: str, value: Any, ttl: int):
        expires_at = time.time() + ttl
        self._cache[key] = (value, expires_at)
    
    async def delete(self, key: str):
        self._cache.pop(key, None)
    
    async def delete_pattern(self, pattern: str):
        # Simple wildcard matching
        keys_to_delete = [k for k in self._cache if pattern.replace('*', '') in k]
        for key in keys_to_delete:
            del self._cache[key]

class CacheService:
    """Cache service with pluggable backend."""
    
    def __init__(self, backend: CacheBackend):
        self.backend = backend
    
    def make_key(self, tenant_id: str, store_id: str, resource: str, resource_id: str = '*') -> str:
        """Generate cache key: {tenant}:{store}:{resource}:{id}"""
        return f"{tenant_id}:{store_id}:{resource}:{resource_id}"
    
    async def get(self, key: str) -> Any | None:
        value = await self.backend.get(key)
        logger.debug(f"Cache {'HIT' if value else 'MISS'}: {key}")
        return value
    
    async def set(self, key: str, value: Any, ttl: int):
        await self.backend.set(key, value, ttl)
    
    async def invalidate_resource(self, tenant_id: str, store_id: str, resource: str, resource_id: str = '*'):
        """Invalidate specific resource and list caches."""
        # Invalidate specific resource
        await self.backend.delete(self.make_key(tenant_id, store_id, resource, resource_id))
        # Invalidate list caches
        await self.backend.delete_pattern(f"{tenant_id}:{store_id}:{resource}:list:")
```

### 1.8 Validation

```bash
# Phase 0-1 exit validation
pytest tests/unit/test_crypto.py tests/unit/test_config.py -v
docker build -t orderdesk-mcp-server:test .
docker run --rm -e MCP_KMS_KEY=$(openssl rand -base64 32) orderdesk-mcp-server:test
```

---

## Step 2: MCP Tools (Wide First, Deep on Orders)

**Goal:** Implement all MCP tools with complete schemas and full OrderDesk API coverage

**Duration:** ~120 hours (Phase 1-4)  
**Dependencies:** Step 1 complete  
**Strategy:** Wide coverage first (all resources), then deep optimization

### 2.1 Store Management Tools (Phase 1)

```python
# mcp_server/routers/stores.py
from mcp import Tool
from pydantic import BaseModel, Field

class StoresRegisterParams(BaseModel):
    store_id: str = Field(..., description="OrderDesk store ID from Settings > API")
    api_key: str = Field(..., description="OrderDesk API key")
    store_name: str | None = Field(None, description="Friendly name (defaults to store_id)")
    label: str | None = Field(None, description="Optional label (e.g., 'Production', 'Staging')")
    
    class Config:
        json_schema_extra = {
            "example": {
                "store_id": "12345",
                "api_key": "your-api-key-here",
                "store_name": "my-main-store",
                "label": "Production"
            }
        }

@Tool(
    name="stores.register",
    description="Register an OrderDesk store with your tenant account. Get credentials from OrderDesk Settings > API."
)
async def register_store(params: StoresRegisterParams) -> dict:
    """Register new store with encrypted credentials."""
    ctx = get_context()
    if not ctx.tenant_id:
        raise AuthError("Not authenticated. Call tenant.use_master_key first.")
    
    # Encrypt API key
    store_service = StoreService()
    store = await store_service.register_store(
        tenant_id=ctx.tenant_id,
        store_id=params.store_id,
        api_key=params.api_key,
        store_name=params.store_name or params.store_id,
        label=params.label,
        tenant_key=ctx.tenant_key
    )
    
    return {
        "status": "success",
        "store_id": store.store_id,
        "store_name": store.store_name,
        "message": f"Store '{store.store_name}' registered successfully"
    }
```

### 2.2 Orders Read Operations (Phase 2)

```python
# mcp_server/routers/orders.py
class OrdersListParams(BaseModel):
    """
    List orders with full filtering and pagination control.
    Maps to: GET https://app.orderdesk.me/api/v2/orders
    Docs: https://apidocs.orderdesk.com/#get-multiple-orders
    """
    store_name: str | None = Field(None, description="Store name (optional if active store set)")
    folder_id: str | None = Field(None, description="OrderDesk folder ID. Get from store.get_settings()")
    status: str | None = Field(None, description="Order status filter")
    since: str | None = Field(None, description="ISO8601 datetime. Return orders updated since this time.")
    sort: str | None = Field(None, description="Sort: 'date_added' or 'date_updated'")
    limit: int = Field(50, ge=1, le=250, description="Max records per page (1-250)")
    page: int = Field(1, ge=1, description="Page number starting at 1")
    search: str | None = Field(None, description="Free text search query")
    # TODO: Add ALL other documented OrderDesk params from API docs
    
    class Config:
        json_schema_extra = {
            "example": {
                "store_name": "my-store",
                "folder_id": "21654",
                "limit": 100,
                "page": 1,
                "since": "2025-10-01T00:00:00Z"
            }
        }

@Tool(name="orders.list")
async def list_orders(params: OrdersListParams) -> dict:
    """List orders with full pagination and filtering control."""
    # Resolve store
    store = await resolve_active_store(params.store_name)
    
    # Check cache
    cache_key = cache_service.make_key(
        ctx.tenant_id, store.store_id, "orders", f"list:{hash(params)}"
    )
    cached = await cache_service.get(cache_key)
    if cached:
        return cached
    
    # Call OrderDesk API
    client = OrderDeskClient(store.store_id, await decrypt_api_key(store))
    response = await client.get("orders", params.dict(exclude_none=True))
    
    # Cache result
    await cache_service.set(cache_key, response, settings.cache_ttl_orders)
    
    return {
        "status": "success",
        "orders": response.get("orders", []),
        "total": response.get("total"),
        "page": params.page,
        "limit": params.limit
    }
```

### 2.3 Mutation Engine (Phase 3)

```python
# mcp_server/services/mutation.py
import asyncio
import random
from copy import deepcopy

class MutationEngine:
    """Engine for safe order mutations with concurrency handling."""
    
    async def mutate_order(
        self,
        client: OrderDeskClient,
        order_id: str,
        mutation: dict | None = None,
        ops: list[dict] | None = None,
        max_retries: int = 5
    ) -> dict:
        """
        Safely mutate order with fetch→mutate→upload and retry.
        
        Flow:
        1. Fetch current order from OrderDesk
        2. Apply mutation (deep merge) or operations (typed)
        3. Upload full order to OrderDesk
        4. On conflict: refetch and retry with exponential backoff
        """
        for attempt in range(max_retries):
            # 1. Fetch current order
            fetched = await client.get(f"orders/{order_id}")
            original_date_updated = fetched.get('date_updated')
            
            # 2. Apply mutation or operations
            if mutation:
                updated = self._deep_merge(fetched, mutation)
            elif ops:
                updated = self._apply_operations(fetched, ops)
            else:
                raise ValueError("Must provide mutation or ops")
            
            # 3. Upload full order
            try:
                result = await client.put(f"orders/{order_id}", updated)
                logger.info(f"Order {order_id} mutated successfully")
                return result
                
            except Exception as e:
                # Check if it's a concurrency conflict
                if self._is_conflict(e):
                    # Exponential backoff with jitter
                    wait = (0.5 * (2 ** attempt)) + random.uniform(0, 0.5)
                    logger.warning(f"Concurrency conflict, retrying in {wait}s (attempt {attempt+1}/{max_retries})")
                    await asyncio.sleep(wait)
                    continue
                else:
                    raise
        
        raise ConflictError(f"Max retries ({max_retries}) exceeded for order {order_id}")
    
    def _deep_merge(self, base: dict, mutation: dict) -> dict:
        """Deep merge mutation into base order."""
        result = deepcopy(base)
        for key, value in mutation.items():
            if isinstance(value, dict) and key in result and isinstance(result[key], dict):
                result[key] = self._deep_merge(result[key], value)
            else:
                result[key] = value
        return result
    
    def _apply_operations(self, order: dict, ops: list[dict]) -> dict:
        """Apply typed operations sequentially."""
        result = deepcopy(order)
        for op in ops:
            op_type = op.get('op')
            if op_type == 'move_folder':
                result['folder_id'] = op['destination_folder_id']
            elif op_type == 'add_items':
                result['order_items'].extend(op['items'])
            elif op_type == 'update_address':
                address_type = op['address_type']
                result[address_type] = op['address']
            # Add more operation types as needed
        return result
    
    def _is_conflict(self, error: Exception) -> bool:
        """Detect concurrency conflict from error."""
        # Check error message for conflict indicators
        error_msg = str(error).lower()
        return 'conflict' in error_msg or 'concurrent' in error_msg or 'modified' in error_msg
```

### 2.4 orders.mutate_full Tool

```python
# mcp_server/routers/orders.py
from pydantic import model_validator

class OrderMutationParams(BaseModel):
    """
    Safely mutate order with automatic conflict resolution.
    Uses fetch → mutate → upload pattern with retry.
    """
    store_name: str | None = None
    order_id: str = Field(..., description="OrderDesk order ID")
    mutation: dict | None = Field(None, description="Object to deep-merge into order (use this OR ops)")
    ops: list[dict] | None = Field(None, description="Typed operations array (use this OR mutation)")
    
    @model_validator(mode='after')
    def validate_xor(self):
        if self.mutation and self.ops:
            raise ValueError("Provide mutation OR ops, not both")
        if not self.mutation and not self.ops:
            raise ValueError("Must provide mutation OR ops")
        return self
    
    class Config:
        json_schema_extra = {
            "examples": [
                {
                    "order_id": "26211",
                    "mutation": {
                        "email": "newemail@example.com",
                        "shipping": {"address1": "123 New St"}
                    }
                },
                {
                    "order_id": "26211",
                    "ops": [
                        {"op": "move_folder", "destination_folder_id": "21655"},
                        {"op": "add_items", "items": [{"name": "New Product", "price": 10.0}]}
                    ]
                }
            ]
        }

@Tool(name="orders.mutate_full")
async def mutate_full(params: OrderMutationParams) -> dict:
    """Safely mutate order with fetch-mutate-upload and automatic retry."""
    store = await resolve_active_store(params.store_name)
    client = OrderDeskClient(store.store_id, await decrypt_api_key(store))
    
    # Use mutation engine
    engine = MutationEngine()
    result = await engine.mutate_order(
        client,
        params.order_id,
        mutation=params.mutation,
        ops=params.ops,
        max_retries=settings.mutation_max_retries
    )
    
    # Invalidate cache
    await cache_service.invalidate_resource(
        ctx.tenant_id, store.store_id, "order", params.order_id
    )
    
    return {
        "status": "success",
        "order": result,
        "message": f"Order {params.order_id} updated successfully"
    }
```

### 2.5 Convenience Wrappers

```python
# mcp_server/routers/orders.py (continued)
@Tool(name="orders.move_folder")
async def move_folder(
    order_ids: list[str],
    destination_folder_id: str | None = None,
    destination_folder_name: str | None = None,
    store_name: str | None = None
) -> dict:
    """
    Move order(s) to folder using OrderDesk batch endpoint.
    Maps to: POST https://app.orderdesk.me/api/v2/move-orders
    """
    if not destination_folder_id and not destination_folder_name:
        raise ValidationError("Must provide destination_folder_id OR destination_folder_name")
    
    store = await resolve_active_store(store_name)
    client = OrderDeskClient(store.store_id, await decrypt_api_key(store))
    
    payload = {"order_id_list": order_ids}
    if destination_folder_id:
        payload["destination_folder_id"] = int(destination_folder_id)
    else:
        payload["destination_folder_name"] = destination_folder_name
    
    result = await client.post("move-orders", payload)
    
    # Invalidate cache for all moved orders
    for order_id in order_ids:
        await cache_service.invalidate_resource(ctx.tenant_id, store.store_id, "order", order_id)
    
    return result
```

### 2.6 Ancillary Resources (Phase 4)

Implement following same pattern:
- `routers/order_items.py` - order_items.list/get/create/update/delete
- `routers/shipments.py` - shipments.list/get/create/update/delete/batch_create
- `routers/products.py` - products.list/get/create/update/delete/batch_update
- `routers/folders.py` - folders.list (wrapper around store.get_settings)

---

## Step 3: Optional HTTP Adapter

**Goal:** Vendor-agnostic HTTP/SSE/WSS transport for web clients

**Duration:** ~30 hours (Phase 5, part 1)  
**Dependencies:** Step 1 complete  
**Feature Flag:** Can be implemented in parallel with Step 2

### 3.1 FastAPI Adapter

```python
# mcp_server/http_adapter.py
from fastapi import FastAPI, Header, WebSocket
from fastapi.responses import StreamingResponse
import asyncio

app = FastAPI(
    title="OrderDesk MCP Server",
    version="0.1.0",
    docs_url="/docs" if settings.enable_webui else None  # Disable in MCP-only mode
)

@app.get("/health")
async def health():
    """Health check endpoint."""
    return {
        "status": "ok",
        "version": "0.1.0",
        "mcp_enabled": True,
        "webui_enabled": settings.enable_webui
    }

@app.get("/metrics")
async def metrics():
    """Prometheus-format metrics."""
    # TODO: Implement metrics collection
    return "# OrderDesk MCP Server Metrics\n"

@app.get("/mcp/sse")
async def mcp_sse(authorization: str = Header(None)):
    """Server-Sent Events transport for MCP."""
    # Authenticate with master key from Authorization header
    if not authorization or not authorization.startswith("Bearer "):
        raise AuthError("Missing or invalid Authorization header")
    
    master_key = authorization.replace("Bearer ", "")
    tenant = await tenant_service.authenticate(master_key)
    if not tenant:
        raise AuthError("Invalid master key")
    
    async def event_generator():
        # Stream MCP messages
        # TODO: Implement MCP message streaming
        yield "data: {}\n\n"
    
    return StreamingResponse(event_generator(), media_type="text/event-stream")
```

---

## Step 4: WebUI (Feature-Flagged)

**Goal:** Admin interface for store management and API testing

**Duration:** ~120 hours (Phase 5-6)  
**Dependencies:** Step 3 complete (HTTP adapter)  
**Feature Flag:** `ENABLE_WEBUI=true`

### 4.1 WebUI Shell & Authentication

```python
# mcp_server/webui/app.py
from fastapi import FastAPI, Request, Depends
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles

webui_app = FastAPI()
templates = Jinja2Templates(directory="mcp_server/webui/templates")
webui_app.mount("/static", StaticFiles(directory="mcp_server/webui/static"), name="static")

# CSRF middleware
@webui_app.middleware("http")
async def csrf_middleware(request: Request, call_next):
    if request.method in ["POST", "PUT", "DELETE"]:
        # Validate CSRF token
        token = request.headers.get("X-CSRF-Token") or request.form.get("csrf_token")
        if not validate_csrf_token(token, request):
            return JSONResponse({"error": "Invalid CSRF token"}, status_code=403)
    response = await call_next(request)
    return response
```

### 4.2 Magic Link Login

```python
# mcp_server/webui/routes/auth.py
from fastapi import APIRouter, Form
from mcp_server.services.email import EmailService

auth_router = APIRouter(prefix="/auth")

@auth_router.post("/login")
async def send_login_link(email: str = Form(...)):
    """Send magic link to email for login."""
    # Rate limit check
    if not await rate_limiter.check_webui_login(get_client_ip(request)):
        raise RateLimitError("Too many login attempts. Try again later.")
    
    # Generate magic link
    token = secrets.token_urlsafe(32)
    token_hash = hashlib.sha256(token.encode()).hexdigest()
    
    # Store in database
    magic_link = MagicLink(
        email=email,
        token=token,
        token_hash=token_hash,
        purpose='login',
        expires_at=datetime.utcnow() + timedelta(minutes=15),
        ip_address=get_client_ip(request)
    )
    db.add(magic_link)
    await db.commit()
    
    # Send email
    email_service = EmailService()
    await email_service.send_magic_link(
        email=email,
        token=token,
        purpose='login'
    )
    
    return {"status": "success", "message": "Magic link sent to email"}
```

### 4.3 API Test Console

```python
# mcp_server/webui/routes/console.py
from fastapi import APIRouter

console_router = APIRouter(prefix="/console")

@console_router.get("/")
async def console_ui(request: Request):
    """Render API Test Console."""
    # Get tool schemas
    tools = await get_all_tool_schemas()
    
    # Get user's stores
    stores = await store_service.list_stores(get_current_tenant(request))
    
    return templates.TemplateResponse("console/index.html", {
        "request": request,
        "tools": tools,
        "stores": stores,
        "csrf_token": generate_csrf_token(request)
    })

@console_router.post("/execute")
async def execute_api_call(
    tool_name: str = Form(...),
    store_id: str = Form(...),
    parameters: str = Form(...)  # JSON string
):
    """Execute API call via backend and return response."""
    import time
    start_time = time.time()
    
    # Parse parameters
    params = json.loads(parameters)
    
    # Get store credentials
    store = await store_service.get_store(get_current_tenant(), store_id)
    client = OrderDeskClient(store.store_id, await decrypt_api_key(store))
    
    # Build request based on tool
    # TODO: Map tool name to OD endpoint and method
    endpoint, method = map_tool_to_endpoint(tool_name)
    
    # Execute request
    try:
        if method == "GET":
            response = await client.get(endpoint, params)
        elif method == "POST":
            response = await client.post(endpoint, params)
        # ... handle other methods
        
        duration_ms = int((time.time() - start_time) * 1000)
        
        # Log to audit
        await audit_service.log_tool_call(
            tenant_id=get_current_tenant(),
            store_id=store_id,
            tool_name=tool_name,
            parameters=params,
            status="success",
            duration_ms=duration_ms,
            source="webui",
            ip_address=get_client_ip(),
            user_agent=request.headers.get("User-Agent")
        )
        
        return {
            "status": "success",
            "response": response,
            "duration_ms": duration_ms,
            "correlation_id": correlation_id_var.get()
        }
        
    except Exception as e:
        duration_ms = int((time.time() - start_time) * 1000)
        
        # Log error to audit
        await audit_service.log_tool_call(
            tenant_id=get_current_tenant(),
            store_id=store_id,
            tool_name=tool_name,
            parameters=params,
            status="error",
            error_message=str(e),
            duration_ms=duration_ms,
            source="webui"
        )
        
        raise
```

### 4.4 API Console Template (Example: HTMX + Tailwind)

```html
<!-- mcp_server/webui/templates/console/index.html -->
{% extends "base.html" %}

{% block content %}
<div class="container mx-auto p-4">
  <h1 class="text-2xl font-bold mb-4">API Test Console</h1>
  
  <div class="grid grid-cols-3 gap-4">
    <!-- Left: Store & Tool Selector -->
    <div class="col-span-1 space-y-4">
      <div>
        <label class="block font-semibold mb-2">Select Store</label>
        <select name="store_id" class="w-full border rounded p-2">
          {% for store in stores %}
          <option value="{{ store.store_id }}">{{ store.store_name }}</option>
          {% endfor %}
        </select>
      </div>
      
      <div>
        <label class="block font-semibold mb-2">Select Tool</label>
        <select name="tool_name" class="w-full border rounded p-2"
                hx-get="/console/params" hx-target="#params-form">
          {% for tool in tools %}
          <option value="{{ tool.name }}">{{ tool.name }}</option>
          {% endfor %}
        </select>
      </div>
    </div>
    
    <!-- Middle: Parameter Form -->
    <div class="col-span-1" id="params-form">
      <!-- Dynamic form generated from tool schema -->
      <h3 class="font-semibold mb-2">Parameters</h3>
      <div class="space-y-2">
        <!-- Pagination quick-fill for list endpoints -->
        <div class="flex gap-2">
          <button class="px-2 py-1 bg-gray-200 rounded" onclick="setLimit(10)">10</button>
          <button class="px-2 py-1 bg-gray-200 rounded" onclick="setLimit(25)">25</button>
          <button class="px-2 py-1 bg-gray-200 rounded" onclick="setLimit(50)">50</button>
          <button class="px-2 py-1 bg-gray-200 rounded" onclick="setLimit(100)">100</button>
        </div>
        
        <!-- Dynamic fields from schema -->
      </div>
      
      <button hx-post="/console/execute" hx-target="#response-pane"
              class="mt-4 px-4 py-2 bg-blue-600 text-white rounded">
        Try It
      </button>
    </div>
    
    <!-- Right: Response Display -->
    <div class="col-span-1" id="response-pane">
      <h3 class="font-semibold mb-2">Response</h3>
      <div class="border rounded p-4 bg-gray-50">
        <div id="response-status" class="mb-2"></div>
        <div id="response-headers" class="text-sm text-gray-600 mb-2"></div>
        <pre id="response-body" class="overflow-auto max-h-96"></pre>
        <div class="mt-2 text-sm">
          <span>Duration: <strong id="response-duration"></strong>ms</span>
          <span class="ml-4">Correlation ID: <strong id="correlation-id"></strong></span>
        </div>
        <div class="mt-4 flex gap-2">
          <button onclick="copyCurl()" class="px-2 py-1 bg-gray-200 rounded text-sm">Copy cURL</button>
          <button onclick="copyJSON()" class="px-2 py-1 bg-gray-200 rounded text-sm">Copy JSON</button>
          <button onclick="copyMCP()" class="px-2 py-1 bg-gray-200 rounded text-sm">Copy MCP Call</button>
        </div>
      </div>
    </div>
  </div>
</div>
{% endblock %}
```

### 4.5 Trace Viewer

```python
# mcp_server/webui/routes/traces.py
from fastapi import APIRouter, Query

traces_router = APIRouter(prefix="/traces")

@traces_router.get("/")
async def traces_ui(request: Request):
    """Render trace viewer."""
    return templates.TemplateResponse("traces/index.html", {
        "request": request,
        "csrf_token": generate_csrf_token(request)
    })

@traces_router.get("/api")
async def query_traces(
    store_id: str | None = Query(None),
    tool_name: str | None = Query(None),
    status: str | None = Query(None),
    since: str | None = Query(None),
    until: str | None = Query(None),
    limit: int = Query(50, ge=1, le=100),
    page: int = Query(1, ge=1)
):
    """Query audit logs with filters."""
    tenant_id = get_current_tenant()
    
    # Build query
    query = db.query(AuditLog).filter(AuditLog.tenant_id == tenant_id)
    
    if store_id:
        query = query.filter(AuditLog.store_id == store_id)
    if tool_name:
        query = query.filter(AuditLog.tool_name == tool_name)
    if status:
        query = query.filter(AuditLog.status == status)
    if since:
        query = query.filter(AuditLog.created_at >= since)
    if until:
        query = query.filter(AuditLog.created_at <= until)
    
    # Paginate
    total = query.count()
    traces = query.order_by(AuditLog.created_at.desc()) \
                 .offset((page - 1) * limit) \
                 .limit(limit) \
                 .all()
    
    return {
        "traces": [trace.to_dict() for trace in traces],
        "total": total,
        "page": page,
        "limit": limit
    }
```

---

## Step 5: Public Signup (Optional)

**Goal:** Self-service tenant creation with master key issuance

**Duration:** ~25 hours (Phase 6)  
**Dependencies:** Step 4 complete (WebUI)  
**Feature Flag:** `ENABLE_PUBLIC_SIGNUP=true`

### 5.1 Signup Flow

```python
# mcp_server/webui/routes/auth.py (additions)
@auth_router.post("/signup")
async def send_signup_link(email: str = Form(...)):
    """Send magic link for signup."""
    # Rate limit
    if not await rate_limiter.check_webui_signup(get_client_ip()):
        raise RateLimitError("Too many signup attempts")
    
    # Generate token
    token = secrets.token_urlsafe(32)
    token_hash = hashlib.sha256(token.encode()).hexdigest()
    
    # Store magic link
    magic_link = MagicLink(
        email=email,
        token=token,
        token_hash=token_hash,
        purpose='signup',
        expires_at=datetime.utcnow() + timedelta(minutes=15)
    )
    db.add(magic_link)
    await db.commit()
    
    # Send email
    await email_service.send_magic_link(email, token, purpose='signup')
    
    return {"status": "success", "message": "Signup link sent"}

@auth_router.get("/signup/verify/{token}")
async def verify_signup(token: str):
    """Verify signup magic link and create tenant."""
    # Validate token
    token_hash = hashlib.sha256(token.encode()).hexdigest()
    magic_link = db.query(MagicLink).filter_by(token_hash=token_hash).first()
    
    if not magic_link or magic_link.used or magic_link.expires_at < datetime.utcnow():
        raise AuthError("Invalid or expired token")
    
    # Generate master key
    master_key = secrets.token_urlsafe(32)
    
    # Create tenant
    tenant = await tenant_service.create_tenant(master_key)
    
    # Mark magic link as used
    magic_link.used = True
    magic_link.used_at = datetime.utcnow()
    magic_link.tenant_id = tenant.id
    await db.commit()
    
    # Create session
    session = await session_service.create_session(tenant.id, request)
    
    # Render page with master key (displayed ONCE)
    return templates.TemplateResponse("auth/signup_complete.html", {
        "request": request,
        "master_key": master_key,
        "master_key_prefix": master_key[:8],
        "warning": "Save this key securely. It will not be shown again."
    })
```

### 5.2 Master Key Rotation

```python
# mcp_server/webui/routes/settings.py
@settings_router.post("/keys/generate")
async def generate_master_key():
    """Generate new master key with grace period."""
    tenant_id = get_current_tenant()
    
    # Generate new key
    new_master_key = secrets.token_urlsafe(32)
    
    # Store metadata
    metadata = MasterKeyMetadata(
        tenant_id=tenant_id,
        master_key_prefix=new_master_key[:8],
        label="Auto-generated",
        created_at=datetime.utcnow()
    )
    db.add(metadata)
    await db.commit()
    
    # Schedule old key revocation (7 days grace period)
    # TODO: Implement background task
    
    return {
        "status": "success",
        "master_key": new_master_key,  # Displayed ONCE
        "prefix": new_master_key[:8],
        "message": "New master key generated. Old key valid for 7 more days."
    }
```

---

## Step 6: Documentation, Examples, CI

**Goal:** Enable first-run success for both MCP and WebUI paths

**Duration:** ~40 hours (Phase 7)  
**Dependencies:** Steps 2-5 complete  

### 6.1 README.md Structure

```markdown
# OrderDesk MCP Server + Optional WebUI

Native MCP server for OrderDesk API with multi-tenant security and optional web interface.

## Quick Start (MCP stdio)

1. Generate encryption key:
   ```bash
   export MCP_KMS_KEY=$(openssl rand -base64 32)
   ```

2. Run server:
   ```bash
   docker-compose up
   # OR
   python -m mcp_server.main
   ```

3. Test connection (via Claude/Cursor):
   ```json
   {"method": "tools/list"}
   ```

4. Authenticate:
   ```json
   {"method": "tools/call", "params": {"name": "tenant.use_master_key", "arguments": {"master_key": "your-key"}}}
   ```

⏱️ **Time to first success: <5 minutes**

## Quick Start (WebUI - Optional)

1. Enable WebUI and configure email:
   ```bash
   export ENABLE_WEBUI=true
   export JWT_SECRET_KEY=$(openssl rand -base64 32)
   export SMTP_HOST=smtp.example.com
   export SMTP_USER=noreply@example.com
   export SMTP_PASSWORD=your-smtp-password
   ```

2. Start server:
   ```bash
   docker-compose up
   ```

3. Open browser: `http://localhost:8080/`

4. Enter email for magic link → check email → click link → save master key

5. Register your first OrderDesk store

6. Navigate to API Console → execute orders.list

⏱️ **Time to first API call: <2 minutes**

[Continue with full README sections...]
```

### 6.2 Examples

Create these files in `examples/`:

```json
// examples/orders_list.json
{
  "description": "List orders with custom pagination",
  "tool": "orders.list",
  "request": {
    "store_name": "my-store",
    "folder_id": "21654",
    "limit": 100,
    "page": 1,
    "since": "2025-10-01T00:00:00Z"
  },
  "notes": [
    "Use limit parameter to control page size (1-250)",
    "Get folder_id from store.get_settings()",
    "since parameter is ISO8601 datetime"
  ]
}
```

```json
// examples/orders_mutate_full.json
{
  "description": "Safely update order with concurrency handling",
  "tool": "orders.mutate_full",
  "request": {
    "order_id": "26211",
    "mutation": {
      "email": "newemail@example.com",
      "shipping": {
        "address1": "123 New Street"
      }
    }
  },
  "notes": [
    "Uses fetch→mutate→upload pattern",
    "Automatically retries on concurrency conflicts (max 5 attempts)",
    "Deep merges mutation into existing order"
  ]
}
```

### 6.3 CI Pipeline

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install deps
        run: pip install ruff black mypy
      - name: Lint
        run: ruff check .
      - name: Format check
        run: black --check .
      - name: Type check
        run: mypy mcp_server/

  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install deps
        run: pip install -e .[dev]
      - name: Run tests
        run: pytest tests/unit/ --cov=mcp_server --cov-report=term-missing --cov-fail-under=80
      - name: Upload coverage
        uses: codecov/codecov-action@v3

  docker:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Build Docker image
        run: docker build -t orderdesk-mcp-server:test .
      - name: Test Docker image
        run: docker run --rm -e MCP_KMS_KEY=$(openssl rand -base64 32) orderdesk-mcp-server:test python -c "import mcp_server; print('OK')"
```

---

## Definition of Done

### Core MCP Functionality (Required for v0.1.0)

#### 1. MCP Tools Operational
- ✅ stdio transport functional with Claude/Cursor
- ✅ All tools discoverable via `tools/list`
- ✅ Tool schemas include `required` fields and examples
- ✅ All documented OrderDesk parameters exposed (no silent truncation)
- ✅ Validation errors list missing fields with minimal example

**Validation:**
```bash
# Test stdio transport
echo '{"jsonrpc":"2.0","id":1,"method":"tools/list"}' | python -m mcp_server.main

# Verify tool schemas
python scripts/validate_tool_schemas.py

# Check pagination parameters
grep -r "class.*ListParams" mcp_server/routers/ | xargs grep -L "limit.*Field.*le=250" && echo "FAIL" || echo "PASS"
```

#### 2. Authentication & Security
- ✅ Master key authentication works
- ✅ Store registration encrypts API keys (verified in DB)
- ✅ Secrets never in logs (automated test passes)
- ✅ Per-tenant rate limiting enforced
- ✅ Session context persists tenant + active store

**Validation:**
```bash
# Test authentication
pytest tests/unit/test_auth.py -v

# Verify encryption
sqlite3 data/app.db "SELECT api_key_ciphertext FROM stores LIMIT 1" | grep -v "^your-api-key" && echo "PASS: Encrypted" || echo "FAIL: Plaintext"

# Verify no secrets in logs
pytest tests/unit/test_security.py::test_log_redaction -v
tail -100 logs/app.log | grep -E "master_key|api_key" && echo "FAIL: Secret leaked" || echo "PASS: Redacted"
```

#### 3. Mutation Safety
- ✅ All mutations use fetch → mutate → full-upload
- ✅ No partial update (PATCH) operations exist
- ✅ Concurrency retry proven (simulated conflicts pass tests)
- ✅ Cache invalidated on all writes

**Validation:**
```bash
# Verify no PATCH operations
grep -ri "patch" mcp_server/routers/ && echo "FAIL: Partial update found" || echo "PASS: Full updates only"

# Test concurrency retry
pytest tests/unit/test_mutation_retry.py -v

# Test cache invalidation
pytest tests/unit/test_cache_invalidation.py -v
```

#### 4. Testing & CI
- ✅ Unit test coverage > 80% overall, > 90% critical paths
- ✅ Integration tests pass (if OrderDesk credentials provided)
- ✅ CI pipeline green (lint, type, test, build)
- ✅ Docker build succeeds and image runs

**Validation:**
```bash
# Coverage check
pytest tests/ --cov=mcp_server --cov-report=term-missing --cov-fail-under=80

# Integration tests (optional)
export ORDERDESK_TEST_ENABLED=true
export ORDERDESK_TEST_STORE_ID=your-test-store
export ORDERDESK_TEST_API_KEY=your-test-key
pytest tests/integration/ -v

# CI simulation
ruff check . && black --check . && mypy mcp_server/ && pytest tests/unit/
docker build -t orderdesk-mcp-server:test .
```

#### 5. Documentation
- ✅ README quickstart enables first-run success in <5 minutes
- ✅ `docs/endpoints.md` catalogs all tools with parameters
- ✅ `docs/operations.md` explains full-update contract, caching, retries
- ✅ Examples include list (with limit/page) and mutate_full flows

**Validation:**
```bash
# Test quickstart (fresh environment)
docker run --rm -e MCP_KMS_KEY=$(openssl rand -base64 32) orderdesk-mcp-server:test
# Should start successfully

# Verify examples are valid JSON
for file in examples/*.json; do jq . $file > /dev/null && echo "$file: OK" || echo "$file: FAIL"; done
```

---

### WebUI Functionality (Required if ENABLE_WEBUI=true)

#### 6. WebUI Admin Operations
- ✅ Login flow works (email → magic link → session)
- ✅ Store management UI functional (register, view, edit, delete, test)
- ✅ Master key displayed once during signup/generation
- ✅ Master key prefix shown in settings (not full key)
- ✅ CSRF protection working on all state-changing requests
- ✅ Rate limiting enforced (login: 5/min, signup: 2/min)

**Validation:**
```bash
# E2E auth test
pytest tests/e2e/test_webui_auth.py --headed

# E2E store management
pytest tests/e2e/test_webui_stores.py --headed

# Manual validation:
# 1. Open http://localhost:8080/
# 2. Enter email
# 3. Check email for magic link
# 4. Click link
# 5. Verify master key displayed with warning
# 6. Try to navigate back
# 7. Verify key NOT visible again
```

#### 7. API Test Console
- ✅ Console shows all OrderDesk tools with complete parameter forms
- ✅ Pagination helpers present (quick-fill buttons: 10, 25, 50, 100)
- ✅ Execute button calls OrderDesk API via backend
- ✅ Response display shows:
  - Request path, method
  - Headers (redacted: API keys, shown: rate limit headers)
  - Request body (formatted JSON)
  - Response status code and message
  - Response body (syntax-highlighted JSON)
  - Duration (milliseconds)
  - Correlation ID (linkable to trace viewer)
- ✅ Copy buttons work: cURL, JSON, MCP tool call
- ✅ Save as template works

**Validation:**
```bash
# E2E console test
pytest tests/e2e/test_api_console.py --headed

# Manual validation:
# 1. Navigate to /console
# 2. Select store
# 3. Select orders.list
# 4. Set limit=25
# 5. Click "Try It"
# 6. Verify response displays:
#    - Status: 200 OK
#    - Headers (X-Tokens-Remaining visible, API key NOT visible)
#    - Response body (JSON with 25 orders)
#    - Duration in milliseconds
#    - Correlation ID
# 7. Click "Copy as cURL"
# 8. Verify cURL in clipboard
# 9. Click "Save as Template"
# 10. Verify template saved
```

#### 8. Trace Viewer
- ✅ Trace viewer lists recent operations
- ✅ Filters work: tenant (auto), store, tool, status, date range
- ✅ Correlation ID links to detail view
- ✅ Detail view shows full request/response (secrets redacted)
- ✅ Clicking correlation ID in console navigates to trace

**Validation:**
```bash
# E2E trace viewer test
pytest tests/e2e/test_trace_viewer.py --headed

# Manual validation:
# 1. Execute API call in console (note correlation ID)
# 2. Navigate to /traces
# 3. Verify call appears in list
# 4. Click correlation ID
# 5. Verify detail view shows:
#    - Tool name
#    - Store
#    - Status (success/error badge)
#    - Duration
#    - Request parameters (API key redacted)
#    - Response (if success)
#    - Error message (if error)
#    - Source: webui
#    - IP address
#    - User agent
# 6. Filter by tool name
# 7. Verify filtered results
```

#### 9. Security Hardening
- ✅ No plaintext secrets anywhere (verified)
- ✅ CSRF on mutating routes (tested)
- ✅ Cookie flags correct: HttpOnly, Secure, SameSite=Strict
- ✅ CSP headers prevent XSS
- ✅ Rate limits prevent abuse
- ✅ Audit log captures all admin actions

**Validation:**
```bash
# Security test suite
pytest tests/unit/test_webui_security.py -v

# CSRF test
pytest tests/unit/test_csrf.py -v

# Rate limit test
pytest tests/unit/test_webui_rate_limit.py -v

# Manual security check:
curl -I http://localhost:8080/ | grep -E "Content-Security-Policy|X-Frame-Options|Set-Cookie.*HttpOnly.*Secure.*SameSite"
```

---

## Implementation Checklist

Use [`speckit.checklist`](./speckit.checklist) for comprehensive validation. Key items:

### Before Starting:
- [ ] Answer critical clarify questions (Q1, Q3, Q4, Q6, Q9, Q11, Q13)
- [ ] Review constitution (design principles)
- [ ] Review specify (technical details)
- [ ] Review analyze (96.4% alignment confirmed)

### After Each Step:
- [ ] Run step-specific validation commands
- [ ] Verify tests pass
- [ ] Update documentation
- [ ] Mark tasks complete in project board

### Before Release:
- [ ] All checklist items pass (target: >90% critical, >80% recommended)
- [ ] Integration tests pass (if credentials available)
- [ ] E2E tests pass (for WebUI)
- [ ] Documentation review (external validator)
- [ ] Security audit (no secrets leaked, CSRF working, rate limits enforced)
- [ ] Performance validation (p95 latency targets met)

---

## Critical Path

### MCP-Only Deployment (Fastest to Production)
```
Step 1 (Foundation) → Step 2 (MCP Tools) → Step 6 (Docs) → Release v0.1.0
Duration: ~240 hours
```

### Full Deployment (with WebUI)
```
Step 1 (Foundation) → Step 2 (MCP Tools) → Step 3 (HTTP) → Step 4 (WebUI) → Step 5 (Signup) → Step 6 (Docs) → Release v0.2.0
Duration: ~395 hours
```

### Parallel Opportunities
- Step 3 (HTTP adapter) can start after Step 1 complete
- Step 6 (documentation) ongoing from Step 2 onward
- Integration tests can run in parallel during Steps 2-5

---

## Validation Commands Reference

### Daily Development
```bash
# Lint and format
ruff check . && black --check .

# Type check
mypy mcp_server/

# Run tests
pytest tests/unit/ -v

# Run specific test
pytest tests/unit/test_auth.py::test_master_key_validation -v
```

### Integration Testing (Optional)
```bash
# Requires OrderDesk test credentials
export ORDERDESK_TEST_ENABLED=true
export ORDERDESK_TEST_STORE_ID=your-test-store-id
export ORDERDESK_TEST_API_KEY=your-test-api-key

pytest tests/integration/ -v
```

### E2E Testing (WebUI)
```bash
# Requires Playwright
pip install playwright
playwright install

# Run E2E tests
pytest tests/e2e/ --headed  # With browser visible
pytest tests/e2e/ --headless  # Headless mode
```

### Docker Validation
```bash
# Build
docker build -t orderdesk-mcp-server:test .

# Run
docker run --rm \
  -e MCP_KMS_KEY=$(openssl rand -base64 32) \
  -p 8080:8080 \
  orderdesk-mcp-server:test

# Health check
curl http://localhost:8080/health

# Logs check
docker logs <container-id> | jq . | grep -E "master_key|api_key" && echo "FAIL" || echo "PASS"
```

---

## Success Metrics

### Functional
- ✅ 100% of documented OrderDesk endpoints mapped
- ✅ All pagination controls exposed to LLM
- ✅ Zero partial update operations
- ✅ Zero credential leakage between tenants

### Non-Functional
- ✅ p95 latency < 500ms (cached reads)
- ✅ p95 latency < 2s (writes)
- ✅ Cache hit rate > 80%
- ✅ Error rate < 5% (excluding invalid requests)
- ✅ WebUI page load < 1s

### Quality
- ✅ Test coverage > 80% overall, > 90% critical paths
- ✅ Zero secrets in logs (automated test)
- ✅ Zero linter/type errors
- ✅ Docker build < 5 minutes
- ✅ First-run success < 5 minutes (MCP) or < 2 minutes (WebUI)

---

## Troubleshooting Implementation

### Common Issues

**Issue: "MCP_KMS_KEY validation failed"**
```bash
# Verify key is valid base64 and >= 32 bytes
echo $MCP_KMS_KEY | base64 -d | wc -c  # Should be >= 32
```

**Issue: "Store registration fails with 400"**
```bash
# Verify OrderDesk credentials are valid
curl "https://app.orderdesk.me/api/v2/test" \
  -H "ORDERDESK-STORE-ID: your-store-id" \
  -H "ORDERDESK-API-KEY: your-api-key"
# Should return: {"status": "success", "message": "Connection Successful"}
```

**Issue: "Mutation max retries exceeded"**
```bash
# Check OrderDesk API status
# Increase MUTATION_MAX_RETRIES if needed
export MUTATION_MAX_RETRIES=10
```

**Issue: "WebUI CSRF token invalid"**
```bash
# Verify CSRF middleware is active
# Check browser cookies for csrf_token
# Ensure form includes hidden csrf_token field
```

---

## Next Steps

1. **Start Implementation:**
   ```bash
   git checkout -b feature/phase-0-bootstrap
   # Follow Step 1.1 (Bootstrap)
   ```

2. **Follow Test-First Approach:**
   - Write test for feature
   - Implement feature
   - Verify test passes
   - Commit with conventional commit message

3. **Validate Continuously:**
   - Run validation commands after each task
   - Check off items in speckit.checklist
   - Update documentation as you go

4. **Submit PRs:**
   - One PR per phase (or logical grouping)
   - Include: code, tests, docs updates
   - Reference task IDs in commits
   - Ensure CI passes before merging

5. **Iterate:**
   - Complete each phase before moving to next
   - Validate exit criteria from plan
   - Update changelog

---

## Reference Quick Links

- **OrderDesk API Docs:** https://apidocs.orderdesk.com/
- **MCP Protocol:** https://modelcontextprotocol.io/
- **Constitution:** [Design Principles](./speckit.constitution)
- **Specification:** [Technical Details](./speckit.specify)
- **Plan:** [8 Phases](./speckit.plan)
- **Tasks:** [150 Tasks](./speckit.tasks.v1.1.md)
- **Checklist:** [300 Validation Items](./speckit.checklist)
- **Analysis:** [96.4% Alignment](./speckit.analyze)

---

**Implementation Roadmap Complete**  
**Status:** Ready to Code  
**Confidence:** Very High (96.4% spec alignment)  
**Next Action:** Begin Phase 0 - Bootstrap & CI

---

**END OF IMPLEMENTATION GUIDE**

